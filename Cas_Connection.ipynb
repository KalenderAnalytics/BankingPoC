{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "1af682d1-d247-4fbf-aa6a-12c8223d4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swat\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import early_stopping\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except BaseException:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "import sasctl.pzmm as pzmm\n",
    "from sasctl import Session\n",
    "from sasctl.services import model_repository as modelRepo\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from pathlib import Path\n",
    "from sasctl.services import model_repository as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f48ebcfa-d6a2-4edc-afcd-b55e79484500",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CAS_CLIENT_SSL_CA_LIST'] = \"C:/Users/turkak/SASVIYACERT/my_ca_certificate.pem\"\n",
    "hostname = 'https://server.demo.sas.com:443/cas-shared-default-http/'\n",
    "username = 'sasdemo'\n",
    "password = 'Orion123'\n",
    "conn = swat.CAS('https://server.demo.sas.com:443/cas-shared-default-http/', username='sasdemo',password='Orion123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "61c3f494-562b-4b0c-9d14-9468464a5752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Grid node action status report: 1 nodes, 9 total actions executed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; About</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>{'CAS': 'Cloud Analytic Services', 'CASCacheLocation': 'CAS Disk Cache', 'CASHostAccountRequired': 'OPTIONAL', 'Copyright': 'Copyright © 2014-2022 SAS Institute Inc. All Rights Reserved.', 'ServerTime': '2022-07-31T05:43:02Z', 'System': {'Hostname': 'controller.sas-cas-server-default.sas-viya.svc.cluster.local', 'Linux Distribution': 'Red Hat Enterprise Linux release 8.6 (Ootpa)', 'Model Number': 'x86_64', 'OS Family': 'LIN X64', 'OS Name': 'Linux', 'OS Release': '3.10.0-1160.6.1.el7.x86_64', 'OS Version': '#1 SMP Tue Nov 17 13:59:11 UTC 2020'}, 'Transferred': 'NO', 'Version': '4.00', 'VersionLong': 'V.04.00M0P07182022', 'Viya Release': '20220721.1658437616927', 'Viya Version': 'Stable 2022.1.3', 'license': {'expires': '22Oct2022:00:00:00', 'gracePeriod': 45, 'site': 'VIYA 4 W ESP, ACCESS, VA, VDMML, AIOT, AND PQA', 'siteNum': 70180938, 'warningPeriod': 49}}</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; nodestatus</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Node Status</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Node Name\">name</th>\n",
       "      <th title=\"Role\">role</th>\n",
       "      <th title=\"Uptime (Sec)\">uptime</th>\n",
       "      <th title=\"Running\">running</th>\n",
       "      <th title=\"Stalled\">stalled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>controller.sas-cas-server-default.sas-viya.svc...</td>\n",
       "      <td>controller</td>\n",
       "      <td>7.419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; server</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Server Status</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Node Count\">nodes</th>\n",
       "      <th title=\"Total Actions\">actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00083s</span> &#183; <span class=\"cas-sys\">sys 0.000803s</span> &#183; <span class=\"cas-memory\">mem 0.322MB</span></small></p>"
      ],
      "text/plain": [
       "[About]\n",
       "\n",
       " {'CAS': 'Cloud Analytic Services',\n",
       "  'CASCacheLocation': 'CAS Disk Cache',\n",
       "  'CASHostAccountRequired': 'OPTIONAL',\n",
       "  'Copyright': 'Copyright © 2014-2022 SAS Institute Inc. All Rights Reserved.',\n",
       "  'ServerTime': '2022-07-31T05:43:02Z',\n",
       "  'System': {'Hostname': 'controller.sas-cas-server-default.sas-viya.svc.cluster.local',\n",
       "   'Linux Distribution': 'Red Hat Enterprise Linux release 8.6 (Ootpa)',\n",
       "   'Model Number': 'x86_64',\n",
       "   'OS Family': 'LIN X64',\n",
       "   'OS Name': 'Linux',\n",
       "   'OS Release': '3.10.0-1160.6.1.el7.x86_64',\n",
       "   'OS Version': '#1 SMP Tue Nov 17 13:59:11 UTC 2020'},\n",
       "  'Transferred': 'NO',\n",
       "  'Version': '4.00',\n",
       "  'VersionLong': 'V.04.00M0P07182022',\n",
       "  'Viya Release': '20220721.1658437616927',\n",
       "  'Viya Version': 'Stable 2022.1.3',\n",
       "  'license': {'expires': '22Oct2022:00:00:00',\n",
       "   'gracePeriod': 45,\n",
       "   'site': 'VIYA 4 W ESP, ACCESS, VA, VDMML, AIOT, AND PQA',\n",
       "   'siteNum': 70180938,\n",
       "   'warningPeriod': 49}}\n",
       "\n",
       "[nodestatus]\n",
       "\n",
       " Node Status\n",
       " \n",
       "                                                 name        role  uptime  running  stalled\n",
       " 0  controller.sas-cas-server-default.sas-viya.svc...  controller   7.419        0        0\n",
       "\n",
       "[server]\n",
       "\n",
       " Server Status\n",
       " \n",
       "    nodes  actions\n",
       " 0      1        9\n",
       "\n",
       "+ Elapsed: 0.00083s, sys: 0.000803s, mem: 0.322mb"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.serverStatus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "2a9b90d1-8dcb-4f6a-b7ff-151b996e7396",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Models'):\n",
    "    os.makedirs('Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "5b6916cd-8740-4e11-aee2-476b9c3fa3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table HMEQ in caslib CASUSER(sasdemo).\n",
      "NOTE: The table HMEQ has been created in caslib CASUSER(sasdemo) from binary data uploaded to Cloud Analytic Services.\n"
     ]
    }
   ],
   "source": [
    "tbl = conn.read_csv(\"./datasets/hmeq.csv\",casout=dict(name='hmeq'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a46f0804-400f-4680-a973-4273ab287cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.170612573623657 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "df = tbl.to_frame()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "73bb026b-1b77-4476-adbb-fc999a9d4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "        \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3acc4656-e45e-4805-819d-7bf8fd02c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c2bb4-5d61-4ad2-89fe-9ca5b808d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_df= pd.DataFrame(tbl.fetch(**fetch_opts)['Fetch'])\n",
    "#pd_df= reduce_mem_usage(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "5c6db885-e8e2-4143-8e33-24aa216d7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.30 Mb (53.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "pd_df= pd.DataFrame(reduce_mem_usage(tbl.to_frame()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "84c547b1-77f1-4a46-99e9-7e2554ba5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.columninfo(table=dict(name='hmeq'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ab3afefc-9277-49cc-b4c2-fdb19ca5ca63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "32be0616-c185-4102-9eca-09f78f9da5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.04 Mb (53.6% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (53.6% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (53.6% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (53.6% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (55.4% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (55.4% reduction)\n",
      "Mem. usage decreased to  0.04 Mb (55.4% reduction)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2d688efa-e5c1-4a7c-85a0-ef341e14757b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3e527378-14ca-4277-9e6f-f773e90c0121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb97f98-d62f-42f8-9644-0b2f47d84a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model= lgb.train(params=lgb_params,train_set=dtrain_set,num_boost_round=1000,valid_sets=dtest_set,early_stopping_rounds=20,verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "d1c7dddf-6656-47a7-957b-d4e8f44a9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_learning(data):\n",
    "    start = time.time()\n",
    "    params = {\n",
    " 'boosting_type': 'gbdt',\n",
    " 'objective': 'binary',\n",
    " 'metric': 'binary_logloss',\n",
    " 'num_leaves': 75,\n",
    " 'learning_rate': 0.05,\n",
    " 'feature_fraction': 0.75,\n",
    " 'bagging_fraction': 0.75,\n",
    " 'bagging_freq': 0,\n",
    " 'min_data_per_group': 10\n",
    "    }\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        data, \n",
    "        data['BAD'], \n",
    "        test_size=0.2)\n",
    "    del data\n",
    "    files = os.listdir('./Models/')\n",
    "\n",
    "    \n",
    "    \n",
    "    dtrain = lgb.Dataset(X_tr, y_tr, free_raw_data=False)\n",
    "    dtest_set = lgb.Dataset(X_te, y_te, free_raw_data=False)\n",
    "\n",
    "    if \"model.pkl\" not in files:\n",
    "        print(\"No Model yet...\")\n",
    "        model = lgb.train(params=params,train_set=dtrain,callbacks=[early_stopping(5)],valid_sets=dtest_set,verbose_eval=10)\n",
    "        with open('./Models/model.pkl', 'wb') as fout:\n",
    "            pickle.dump(model, fout)\n",
    "    \n",
    "    with open('./Models/model.pkl', 'rb') as fin:\n",
    "        pkl_bst = pickle.load(fin)\n",
    "    model = lgb.train(params, \n",
    "                       init_model = pkl_bst,\n",
    "                       train_set = dtrain,\n",
    "                       valid_sets=dtest_set,\n",
    "                       keep_training_booster = True,\n",
    "                      \n",
    "                     callbacks=[early_stopping(5)])\n",
    "    #f1 = f1_score(y_te, model.predict(X_te))\n",
    "    #print(\"f1_score:\", f1)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067acb1-223e-4b14-9c5f-aa0416223468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "aad331ba-84ab-4c1e-bd61-a572420a8bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['REASON', 'JOB']"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "213a24f6-2ff8-4e7a-9fd7-2417e0d50093",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.05 Mb (53.6% reduction)\n",
      "No Model yet...\n",
      "[LightGBM] [Info] Number of positive: 241, number of negative: 559\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1096\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301250 -> initscore=-0.841353\n",
      "[LightGBM] [Info] Start training from score -0.841353\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.31739\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.186606\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.111699\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's binary_logloss: 0.0747869\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.0492777\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's binary_logloss: 0.0328626\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's binary_logloss: 0.0204801\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's binary_logloss: 0.0128278\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's binary_logloss: 0.00833309\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's binary_logloss: 0.00568342\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.00568342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 241, number of negative: 559\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1096\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 13\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 9.68741e-05\n",
      "Mem. usage decreased to  0.05 Mb (53.6% reduction)\n",
      "[LightGBM] [Info] Number of positive: 171, number of negative: 629\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1132\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 13\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's binary_logloss: 2.72154e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.05 Mb (53.6% reduction)\n",
      "[LightGBM] [Info] Number of positive: 162, number of negative: 638\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1136\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 13\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's binary_logloss: 3.04987e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.05 Mb (55.4% reduction)\n",
      "[LightGBM] [Info] Number of positive: 126, number of negative: 674\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1153\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 13\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's binary_logloss: 2.65441e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.05 Mb (55.4% reduction)\n",
      "[LightGBM] [Info] Number of positive: 115, number of negative: 685\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1155\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 13\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's binary_logloss: 2.34601e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.05 Mb (53.6% reduction)\n",
      "[LightGBM] [Info] Number of positive: 137, number of negative: 631\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1308\n",
      "[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 13\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's binary_logloss: 2.43153e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "batch_rows = 1000\n",
    "maxn= 6000\n",
    "dflist = list()\n",
    "for x in batch(range(0, maxn), batch_rows):\n",
    "    fetch_opts = dict(maxrows=maxn,from_=x[0] + 1 ,to=x[0] + batch_rows )\n",
    "    if x[0] ==0:\n",
    "        fetch_opts = dict(maxrows=maxn,from_=x[0]  ,to=x[0] + batch_rows )\n",
    "    df = pd.DataFrame(reduce_mem_usage(tbl.to_frame(**fetch_opts)))\n",
    "    dtypes = df.dtypes\n",
    "    nominals = dtypes[dtypes=='object'].keys().tolist()\n",
    "    if len(nominals) >0:\n",
    "        for col in nominals:\n",
    "            df[col] = df[col].astype('category')\n",
    "    model = incremental_learning(df)\n",
    "    with open('./Models/model.pkl', 'wb') as fout:\n",
    "        pickle.dump(model, fout)\n",
    "    dflist.append(model)    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    #df = pd.DataFrame(tbl.fetch(**fetch_opts)['Fetch'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "0d01e066-3a99-47a3-a312-60b055c5c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('valid_0', 'binary_logloss', 7.979287729799823e-05, False)]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "dde5dc83-4c3e-4b74-a41c-77e826c382a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Model yet...\n",
      "[LightGBM] [Info] Number of positive: 477, number of negative: 1523\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1295\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238500 -> initscore=-1.160921\n",
      "[LightGBM] [Info] Start training from score -1.160921\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.265919\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.15737\n",
      "[30]\tvalid_0's binary_logloss: 0.09427\n",
      "[40]\tvalid_0's binary_logloss: 0.0639783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's binary_logloss: 0.0422747\n",
      "[60]\tvalid_0's binary_logloss: 0.0282196\n",
      "[70]\tvalid_0's binary_logloss: 0.0176691\n",
      "[80]\tvalid_0's binary_logloss: 0.011071\n",
      "[90]\tvalid_0's binary_logloss: 0.00723541\n",
      "[100]\tvalid_0's binary_logloss: 0.0049455\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.0049455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 477, number of negative: 1523\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1295\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 13\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 8.78018e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = incremental_learning(pd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "81c730f6-7677-4e24-a81a-9ad6493d3633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputVar.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\inputVar.json\n",
      "outputVar.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\outputVar.json\n",
      "fileMetaData.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\fileMetaData.json\n",
      "ModelProperties.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\ModelProperties.json\n",
      "dmcas_fitstat.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\dmcas_fitstat.json\n",
      "NOTE: Added action set 'percentile'.\n",
      "NOTE: Cloud Analytic Services made the uploaded file available as table SCOREDVALUES in caslib CASUSER(sasdemo).\n",
      "NOTE: The table SCOREDVALUES has been created in caslib CASUSER(sasdemo) from binary data uploaded to Cloud Analytic Services.\n",
      "dmcas_roc.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\dmcas_roc.json\n",
      "dmcas_lift.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\dmcas_lift.json\n",
      "Model LGB_Model was successfully pickled and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\LGB_Model.pickle.\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\turkak\\AppData\\Local\\Temp\\ipykernel_21044\\2765167922.py\", line 1, in <cell line: 1>\n",
      "    mm_python('OS_PROJECT','LGB_Model',model,'BAD',X_tr,y_tr,'Core Lightgbm Model','Lightgbm')\n",
      "  File \"C:\\Users\\turkak\\AppData\\Local\\Temp\\ipykernel_21044\\3578387189.py\", line 87, in mm_python\n",
      "    modelRepo.import_model_from_zip(model_name, project_name, zipIOFile,version='latest')\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\_services\\model_repository.py\", line 527, in import_model_from_zip\n",
      "    r = cls.post(\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\_services\\service.py\", line 113, in post\n",
      "    return cls.request(\"post\", *args, **kwargs)\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\_services\\service.py\", line 93, in request\n",
      "    return core.request(verb, path, session, format_, **kwargs)\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\core.py\", line 1630, in request\n",
      "    raise HTTPError(\n",
      "urllib.error.HTTPError: HTTP Error 409: {\"errorCode\":21201,\"message\":\"The name \\\"LGB_Model\\\" is already in use in the selected folder. Enter a unique name.\",\"details\":[\"traceId: 5462b22436a785ff\",\"path: /modelRepository/models\"],\"links\":[],\"version\":2,\"httpStatusCode\":409}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1990, in showtraceback\n",
      "    if hasattr(value, \"_render_traceback_\"):\n",
      "  File \"C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\tempfile.py\", line 472, in __getattr__\n",
      "    file = self.__dict__['file']\n",
      "KeyError: 'file'\n"
     ]
    }
   ],
   "source": [
    "mm_python('OS_PROJECT','LGB_Model',model,'BAD',X_tr,y_tr,'Core Lightgbm Model','Lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "22d623a8-6317-4deb-a271-24a25f232cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'sasctl.core.RestObj'>(headers={'Date': 'Sat, 30 Jul 2022 14:18:20 GMT', 'Content-Type': 'application/vnd.sas.models.project+json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Origin, Access-Control-Request-Method, Access-Control-Request-Headers', 'SAS-Service-Response-Flag': 'true', 'Content-Security-Policy': \"default-src 'self'; object-src 'none';\", 'Last-Modified': 'Sat, 30 Jul 2022 14:18:19 GMT', 'ETag': '\"l67zaxl7\"', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '1; mode=block', 'Cache-Control': 'no-cache, no-store, max-age=0, must-revalidate', 'Pragma': 'no-cache', 'Expires': '0', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains', 'X-Frame-Options': 'SAMEORIGIN'}, data={'creationTimeStamp': '2022-07-30T14:18:19.610Z', 'modifiedTimeStamp': '2022-07-30T14:18:19.915Z', 'createdBy': 'sasdemo', 'modifiedBy': 'sasdemo', 'links': [{'method': 'GET', 'rel': 'up', 'href': '/modelRepository/projects', 'uri': '/modelRepository/projects', 'type': 'application/vnd.sas.collection', 'itemType': 'application/vnd.sas.models.project.summary'}, {'method': 'GET', 'rel': 'self', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'type': 'application/vnd.sas.models.project'}, {'method': 'GET', 'rel': 'alternate', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'type': 'application/vnd.sas.models.project.summary'}, {'method': 'DELETE', 'rel': 'delete', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d'}, {'method': 'PUT', 'rel': 'update', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d', 'type': 'application/vnd.sas.models.project'}, {'method': 'GET', 'rel': 'projectVersions', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/projectVersions', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/projectVersions', 'type': 'application/vnd.sas.collection', 'itemType': 'application/vnd.sas.models.project.version'}, {'method': 'GET', 'rel': 'projectModels', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/models', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/models', 'type': 'application/vnd.sas.collection', 'itemType': 'application/vnd.sas.models.model.summary'}, {'method': 'GET', 'rel': 'projectVariables', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/variables', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/variables', 'type': 'application/vnd.sas.collection', 'itemType': 'application/vnd.sas.models.variable.summary'}, {'method': 'GET', 'rel': 'projectHistory', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/history', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/history', 'type': 'application/vnd.sas.collection'}, {'method': 'GET', 'rel': 'championModel', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion', 'type': 'application/vnd.sas.models.model'}, {'method': 'DELETE', 'rel': 'unsetChampion', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion'}, {'method': 'GET', 'rel': 'championScoreCodeJson', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'type': 'text/vnd.sas.models.score.code.raw'}, {'method': 'GET', 'rel': 'championScoreCodeText', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'type': 'text/plain'}, {'method': 'GET', 'rel': 'championDs2packageScoreCode', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'type': 'text/vnd.sas.models.score.code.ds2package'}, {'method': 'GET', 'rel': 'championDs2ScoreCode', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/champion/code', 'type': 'text/vnd.sas.models.score.code.ds2'}, {'method': 'GET', 'rel': 'challengers', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/challengers', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/challengers', 'type': 'application/vnd.sas.collection', 'itemType': 'application/vnd.sas.models.model.summary'}, {'method': 'DELETE', 'rel': 'unsetChallengers', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/challengers', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/challengers'}, {'method': 'GET', 'rel': 'getProjectFiles', 'href': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/contents', 'uri': '/modelRepository/projects/7c186c1f-c2d4-412d-a769-7003589cf28d/contents'}], 'version': 2, 'id': '7c186c1f-c2d4-412d-a769-7003589cf28d', 'name': 'OS_PROJECT', 'location': '/Model Repositories/DMRepository', 'repositoryId': 'f9b3dfd2-a5b7-4825-af5b-e76f43543cf1', 'folderId': '122ef383-a210-48da-a73d-e37ce1ceb543', 'candidateChampionHonored': False, 'targetLevel': '', 'challengerModels': [], 'latestVersion': 'Version 1', 'status': 'prototype', 'tags': [], 'globalTags': []})"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.create_project(project='OS_PROJECT',repository='DMRepository')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5708a7fe-ad83-4a18-9fd1-f0e5c0540cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = 'server.demo.sas.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "aeacb26f-2139-4457-bbc7-4918bf2f7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_python(project_name, model_name, model, target, input_df, actual_df, desc, model_type):      \n",
    "    ##################################################\n",
    "    #input_df[cat_cols] = input_df[cat_cols].astype('str')\n",
    "    # CREATE OUTPUT INFORMATION  \n",
    "\n",
    "    # Output folder name\n",
    "    output_folder = 'Outputs'\n",
    "\n",
    "    # Create Folder\n",
    "    output_path = Path.cwd() / output_folder / model_name\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    ##################################################\n",
    "    # CONNECT TO SAS VIYA\n",
    "    host_session = 'https://' + hostname + '/'\n",
    "    \n",
    "    # Connect using a session \n",
    "   # sess=Session(host_session, username, password, verify_ssl=False, protocol=\"http\")\n",
    "    sess=Session(host_session, username, password)\n",
    "    ##################################################\n",
    "    # COMPILE METADATA\n",
    "\n",
    "    # Create JSON Files Object\n",
    "    JSONFiles = pzmm.JSONFiles()\n",
    "\n",
    "    # Write Input Variable JSON \n",
    "    JSONFiles.writeVarJSON(input_df, isInput=True, jPath=output_path)\n",
    "\n",
    "    # Mock up Output Variables\n",
    "    yCategory = actual_df.astype('str') # Ensuring dataframe length matches\n",
    "    output_df = pd.DataFrame(columns=['EM_EVENTPROBABILITY', 'EM_CLASSIFICATION']) # Ensuring column names are what SAS expects\n",
    "    output_df['EM_CLASSIFICATION'] = yCategory # Ensuring data type is nominal \n",
    "    output_df['EM_EVENTPROBABILITY'] = 0.5 # Ensuring data type is decimal  \n",
    "\n",
    "    # Write Output Variable JSON\n",
    "    JSONFiles.writeVarJSON(output_df, isInput=False, jPath=output_path)\n",
    "\n",
    "    # Write File Metadata JSON\n",
    "    JSONFiles.writeFileMetadataJSON(model_name, jPath=output_path)\n",
    "\n",
    "    # Write Model Properties JSON\n",
    "    JSONFiles.writeModelPropertiesJSON(modelName=model_name, \n",
    "        modelDesc=desc,\n",
    "        targetVariable=target,\n",
    "        modelType=model_type,\n",
    "        modelPredictors=input_df.columns.array,\n",
    "        targetEvent='1',\n",
    "        numTargetCategories=2,\n",
    "        eventProbVar='EM_EVENTPROBABILITY',\n",
    "        jPath=output_path,\n",
    "        modeler=username)\n",
    "\n",
    "    # Get predictions\n",
    "    trainProba = model.predict(input_df)\n",
    "\n",
    "    # Creating Assessment Data \n",
    "    trainData = pd.concat([pd.DataFrame(actual_df).reset_index(drop=True), pd.Series(data=trainProba)], axis=1)\n",
    "\n",
    "    # Write Fit Statistics JSON\n",
    "    JSONFiles.calculateFitStat(trainData=trainData, jPath=output_path)\n",
    "\n",
    "    # Write ROC amd Lift Statistics JSON\n",
    "    JSONFiles.generateROCLiftStat(target, 1, conn, trainData=trainData, jPath=output_path)\n",
    "\n",
    "    ##################################################\n",
    "    # PICKLE MODEL \n",
    "    pzmm.PickleModel.pickleTrainedModel(_, model, model_name, output_path)\n",
    "\n",
    "    ##################################################\n",
    "     #WRITE SCORE CODE \n",
    "\n",
    "    # Generate Score Code Object\n",
    "    ScoreCode = pzmm.ScoreCode()\n",
    "\n",
    "    # Write Score Code\n",
    "    ScoreCode.writeScoreCode(input_df, actual_df, model_name, '{}.predict({})', model_name + '.pickle', pyPath=output_path)\n",
    "\n",
    "    ##################################################\n",
    "    # ZIP FOLDER\n",
    "    \n",
    "    zipIOFile = pzmm.ZipModel.zipFiles(fileDir=output_path, modelPrefix=model_name)\n",
    "\n",
    "    ##################################################\n",
    "    # PUSH ZIP FOLDER INTO MODEL MANAGER\n",
    "    with sess: \n",
    "        modelRepo.import_model_from_zip(model_name, project_name, zipIOFile,version='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7cf3096d-f2d8-47ec-9c12-1704a58bdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    " trainData = pd.concat([pd.DataFrame(y_tr), pd.DataFrame(trainProba)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a4cd4a3e-edcc-4315-a106-4e546092fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        pd_df, \n",
    "        pd_df['BAD'], \n",
    "        test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58587f31-ae65-45e4-91fe-707f318209fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bc17ea56-e079-41e1-b1d2-47cf8f4e0924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n",
      "C:\\Users\\turkak\\Anaconda3\\envs\\akbank_poc\\lib\\site-packages\\sasctl\\pzmm\\writeJSONFiles.py:104: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  outputJSON = outputJSON.append([outputRow], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputVar.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\inputVar.json\n",
      "outputVar.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\outputVar.json\n",
      "fileMetaData.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\fileMetaData.json\n",
      "ModelProperties.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\ModelProperties.json\n",
      "dmcas_fitstat.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\dmcas_fitstat.json\n",
      "NOTE: Added action set 'percentile'.\n",
      "NOTE: Cloud Analytic Services made the uploaded file available as table SCOREDVALUES in caslib CASUSER(sasdemo).\n",
      "NOTE: The table SCOREDVALUES has been created in caslib CASUSER(sasdemo) from binary data uploaded to Cloud Analytic Services.\n",
      "dmcas_roc.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\dmcas_roc.json\n",
      "dmcas_lift.json was successfully written and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\dmcas_lift.json\n",
      "Model LGB_Model was successfully pickled and saved to C:\\Users\\turkak\\Projects\\akbank_poc\\Outputs\\LGB_Model\\LGB_Model.pickle.\n"
     ]
    }
   ],
   "source": [
    "mm_python('OS_PROJECT','LGB_Model',model,'BAD',X_tr,y_tr,'Core Lightgbm Model','Lightgbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

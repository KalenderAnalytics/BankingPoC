{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This is a simple end to end example of how you can use SAS Viya for analysis\n",
    "The example follows these steps:\n",
    "1. Importing the needed Python packages\n",
    "1. Starting a CAS session on an already running CAS server\n",
    "1. Load the needed CAS Action Sets\n",
    "1. Loading data from the local file system to the CAS server\n",
    "1. Explore the data\n",
    "1. Impute missing values\n",
    "1. Partition the data into training and validation partitions\n",
    "1. Build a gradient boost\n",
    "1. Assess the model\n",
    "1. Build ROC and lift charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and initialize\n",
    "\n",
    "Find doc for all the CAS actions [here](http://go.documentation.sas.com/?cdcId=vdmmlcdc&cdcVersion=8.11&docsetId=caspg&docsetTarget=titlepage.htm \n",
    ") \n",
    "\n",
    "### Documentation Links:\n",
    "* [SAS® Viya™ 3.2: System Programming Guide](http://go.documentation.sas.com/?cdcId=vdmmlcdc&cdcVersion=8.11&docsetId=caspg&docsetTarget=titlepage.htm)\n",
    "* [Getting Started with SAS® Viya™ 3.2 for Python](http://go.documentation.sas.com/?cdcId=vdmmlcdc&cdcVersion=8.11&docsetId=caspg3&docsetTarget=titlepage.htm&locale=en)\n",
    "\n",
    "In this code we import the needed packages and we assign variables for the modeling details that will be used later in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import swat\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "target          = \"bad\"\n",
    "class_inputs    = [\"reason\", \"job\"]\n",
    "class_vars      = [target] + class_inputs\n",
    "interval_inputs = [\"im_clage\", \"clno\", \"im_debtinc\", \"loan\", \"mortdue\", \"value\", \"im_yoj\", \"im_ninq\", \"derog\", \"im_delinq\"]\n",
    "all_inputs      = interval_inputs + class_inputs\n",
    "\n",
    "indata = 'hmeq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start CAS session\n",
    "\n",
    "* Documentation to [Connect and Start a Session](http://go.documentation.sas.com/?cdcId=vdmmlcdc&cdcVersion=8.11&docsetId=caspg3&docsetTarget=home.htm&locale=en)\n",
    "\n",
    "In this code we assign values for the cashost, casport, and casauth values. These are then used to establish a CAS session named `sess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cashost='localhost'\n",
    "cashost='localhost'\n",
    "casport=5570\n",
    "casauth='~/.authinfo'\n",
    "sess = swat.CAS(hostname=cashost, port=casport,  authinfo=casauth, caslib=\"casuser\", name=\"brad\")\n",
    "\n",
    "# Load the needed action sets for this example:\n",
    "sess.loadactionset('datastep')\n",
    "sess.loadactionset('datapreprocess')\n",
    "sess.loadactionset('cardinality')\n",
    "sess.loadactionset('sampling')\n",
    "sess.loadactionset('decisiontree')\n",
    "sess.loadactionset('astore')\n",
    "sess.loadactionset('percentile')\n",
    "# show the session details\n",
    "sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into CAS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = sess.CASTable('hmeq')\n",
    "if not indata.tableexists().exists:\n",
    "    indata = sess.upload_file('http://support.sas.com/documentation/onlinedoc/viya/exampledatasets/hmeq.csv', casout=indata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore and Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore data and plot missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.CASTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_data_card = sess.CASTable('data_card', replace=True)\n",
    "\n",
    "indata.cardinality.summarize(cardinality=tbl_data_card)\n",
    "\n",
    "tbl_data_card = tbl_data_card.query('_NMISS_ > 0')\n",
    "tbl_data_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_data_card['PERCENT_MISSING'] = (tbl_data_card['_NMISS_'] / tbl_data_card['_NOBS_']) * 100\n",
    "\n",
    "ax = tbl_data_card[['_VARNAME_', 'PERCENT_MISSING']].to_frame().set_index('_VARNAME_').plot.bar(\n",
    "         title='Percentage of Missing Values', figsize=(15,7)\n",
    "     )\n",
    "ax.set_ylabel('Percent Missing')\n",
    "ax.set_xlabel('Variable Names');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmeq_prepped = sess.CASTable('hmeq_prepped', replace=True)\n",
    "# hmeq_prepped = sess.CASTable('hmeq_prepped', replace=True)\n",
    "\n",
    "indata.datapreprocess.transform(\n",
    "    casout=hmeq_prepped,\n",
    "    copyallvars=True,\n",
    "    outvarsnameglobalprefix='im',\n",
    "    requestpackages=[\n",
    "        {'impute': {'method': 'mean'}, 'inputs': ['clage']},\n",
    "        {'impute': {'method': 'median'}, 'inputs': ['delinq']},\n",
    "        {'impute': {'method': 'value', 'valuesNumeric': [2]}, 'inputs': ['ninq']},\n",
    "        {'impute': {'method': 'value', 'valuesNumeric': [35.0, 7, 2]}, 'inputs': ['debtinc', 'yoj']}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition data into Training and Validation\n",
    "\n",
    "The stratified action in the sampling actionset allows us to create two partition and observe the reponse rate of the target variable `bad` in both training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmeq_part = sess.CASTable('hmeq_part', replace=True)\n",
    "\n",
    "hmeq_prepped.groupby(target).sampling.stratified(\n",
    "  output=dict(casout=hmeq_part, copyvars='all'),\n",
    "  samppct=70,\n",
    "  partind=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "\n",
    "\n",
    "In this code block we do the following:\n",
    "1. Train the decision tree using the variable listed we defined in the setup phase. We save the decision tree model `gb_model`. It is used in the subsequent step but it could just have easily been used a day, week, or month from now.\n",
    "1. Score data using the `gb_model` that was created in the previous step\n",
    "1. Run data step code on the scored output to prepare it for further analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hmeq_part_1 = hmeq_part.query('_partind_ = 1')\n",
    "gb_model = sess.CASTable('gb_model', replace=True)\n",
    "scored_gb = sess.CASTable('_scored_gb', replace=True)\n",
    "gb_model_astore = sess.CASTable('gb_model_astore', replace=True)\n",
    "\n",
    "hmeq_part_1.decisiontree.gbtreetrain(\n",
    "  inputs=all_inputs,\n",
    "  nominals=class_vars,\n",
    "  target=target,\n",
    "  ntree=10,\n",
    "  nbins=20,\n",
    "  maxlevel=6,\n",
    "  varimp=True,\n",
    "  missing='useinsearch',\n",
    "  casout=gb_model,\n",
    "  #save the model state as astore\n",
    "  savestate={\"name\": \"gb_model_astore\",\n",
    "              \"promote\": True,\n",
    "             \"caslib\":\"public\"\n",
    "          }\n",
    ")\n",
    "\n",
    "# Score \n",
    "hmeq_part.decisionTree.gbtreeScore(\n",
    "  modeltable=gb_model,\n",
    "  casout=scored_gb,\n",
    "  copyvars=[target, '_partind_']\n",
    ")\n",
    "\n",
    "gb_model.head()\n",
    "scored_gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "hmeq_part_1.head().to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the model savestate out to the server filesystem\n",
    "gb_model_astore.table.save(name=\"gb_model_astore.bin\", table=dict(name='gb_model_astore',caslib='public'),caslib=\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download results of astore savestate\n",
    "results = sess.aStore.download(rstore=dict(name='gb_model_astore',caslib='public'))\n",
    "list(results.keys())\n",
    "results['blob'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model written to local filesystem \n",
    "import codecs\n",
    "blob = sess.astore.download(rstore=dict(name='gb_model_astore',caslib='public'))['blob']\n",
    "with open(\"Output.bin\",\"wb\") as output_file:\n",
    "    output_file.write(blob)\n",
    "    output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Output.bin\",\"rb\")\n",
    "f.seek(0)\n",
    "data = f.read()\n",
    "f.close()\n",
    "data[2]\n",
    "# results2 = sess.aStore.upload(rstore=dict(name='gb_model_astore_upload',caslib='public'),store=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sess.describe(rstore=dict(name='gb_model_astore',caslib='PUBLIC'))  \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.table.fileinfo(caslib=\"public\",path=\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create p_bad0 and p_bad1 as _gbt_predp_ is the probability of event in _gbt_predname_\n",
    "scored_gb['p_bad1'] = scored_gb.eval(\"ifn( strip(_gbt_predname_) = '1', _gbt_predp_, 1-_gbt_predp_ )\") \n",
    "scored_gb['p_bad0'] = scored_gb.eval(\"ifn( strip(_gbt_predname_) = '0', 1-_gbt_predp_, _gbt_predp_ )\")\n",
    "\n",
    "gb_assess = sess.percentile.assess(\n",
    "            table=scored_gb.query('_partind_ = 0'),\n",
    "            inputs=['p_bad1'],      \n",
    "            response='bad',\n",
    "            event='1',\n",
    "            pvar=['p_bad0'],\n",
    "            pevent=['0']      \n",
    "        )\n",
    " \n",
    "gb_fitstat  = gb_assess.FitStat\n",
    "gb_rocinfo  = gb_assess.ROCInfo\n",
    "gb_liftinfo = gb_assess.LIFTInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ROC and Lift plots (using Validation data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare assessment results for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new variable to indicate type of model\n",
    "gb_liftinfo['model']   = 'GradientBoosting'\n",
    "gb_rocinfo['model']    = 'GradientBoosting'\n",
    "\n",
    "# # Concatenate data\n",
    "# all_liftinfo = pd.concat([rf_liftinfo, gb_liftinfo, nn_liftinfo, tree_liftinfo], ignore_index=True)\n",
    "# all_rocinfo = pd.concat([rf_rocinfo, gb_rocinfo, nn_rocinfo, tree_rocinfo], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw ROC and Lift plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw ROC charts \n",
    "plt.figure(figsize=(15, 5))\n",
    "for key, grp in gb_rocinfo.groupby(['model']):\n",
    "    plt.plot(grp['FPR'], grp['Sensitivity'], label=key)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Draw lift charts\n",
    "plt.figure(figsize=(15, 5))\n",
    "for key, grp in gb_liftinfo.groupby(['model']):\n",
    "    plt.plot(grp['Depth'], grp['CumLift'], label=key)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Cumulative Lift')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Cumulative Lift Chart')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End CAS session\n",
    "\n",
    "This closes the CAS session freeing resources for others to leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as sess.endsession(); sess.close();\n",
    "sess.terminate()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
